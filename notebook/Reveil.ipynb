{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqfhFEM62G4k"
   },
   "source": [
    "# importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1757274822169,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "TenqqAZS2Mpv",
    "outputId": "a78a4f57-e851-47e5-c3a3-1efe348ac2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "    User ID        Username                                              Tweet  \\\n",
      "0   132131           flong  Station activity person against natural majori...   \n",
      "1   289683  hinesstephanie  Authority research natural life material staff...   \n",
      "2   779715      roberttran  Manage whose quickly especially foot none to g...   \n",
      "3   696168          pmason  Just cover eight opportunity strong policy which.   \n",
      "4   704441          noah87                      Animal sign six data good or.   \n",
      "\n",
      "   Retweet Count  Mention Count  Follower Count  Verified  Bot Label  \\\n",
      "0             85              1            2353     False          1   \n",
      "1             55              5            9617      True          0   \n",
      "2              6              2            4363      True          0   \n",
      "3             54              5            2242      True          1   \n",
      "4             26              3            8438     False          1   \n",
      "\n",
      "       Location           Created At            Hashtags  \n",
      "0     Adkinston  2020-05-11 15:29:50                 NaN  \n",
      "1    Sanderston  2022-11-26 05:18:10           both live  \n",
      "2  Harrisonfurt  2022-08-08 03:16:54         phone ahead  \n",
      "3  Martinezberg  2021-08-14 22:27:05  ever quickly new I  \n",
      "4  Camachoville  2020-04-13 21:24:21     foreign mention  \n",
      "\n",
      "Column Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   User ID         50000 non-null  int64 \n",
      " 1   Username        50000 non-null  object\n",
      " 2   Tweet           50000 non-null  object\n",
      " 3   Retweet Count   50000 non-null  int64 \n",
      " 4   Mention Count   50000 non-null  int64 \n",
      " 5   Follower Count  50000 non-null  int64 \n",
      " 6   Verified        50000 non-null  bool  \n",
      " 7   Bot Label       50000 non-null  int64 \n",
      " 8   Location        50000 non-null  object\n",
      " 9   Created At      50000 non-null  object\n",
      " 10  Hashtags        41659 non-null  object\n",
      "dtypes: bool(1), int64(5), object(5)\n",
      "memory usage: 3.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = '../dataset/bot_detection_data.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"First 5 rows:\\n\", df.head())\n",
    "print(\"\\nColumn Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWiRlUR02NVy"
   },
   "source": [
    "# preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1757274822248,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "KFhHfI3N2QPq",
    "outputId": "39794bc3-4f45-4f35-c1e0-8f9f3431e3b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account_age_days  hashtag_count  username_length  digit_count  \\\n",
      "0              1972              0                5            0   \n",
      "1              1044              2               14            0   \n",
      "2              1154              2               10            0   \n",
      "3              1512              4                6            0   \n",
      "4              2000              2                6            2   \n",
      "\n",
      "   tweet_length  retweet_per_hashtag  Mention Count  Follower Count  Verified  \n",
      "0            83            85.000000              1            2353         0  \n",
      "1            77            18.333333              5            9617         1  \n",
      "2            61             2.000000              2            4363         1  \n",
      "3            49            10.800000              5            2242         1  \n",
      "4            29             8.666667              3            8438         0  \n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: Bot Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Datetime conversion\n",
    "df['Created At'] = pd.to_datetime(df['Created At'], errors='coerce', utc=True)\n",
    "now = pd.Timestamp.utcnow().tz_convert('UTC')\n",
    "df['account_age_days'] = (now - df['Created At']).dt.days\n",
    "\n",
    "# handling missing values for hashtags\n",
    "df['Hashtags'] = df['Hashtags'].fillna(\"\")\n",
    "df['hashtag_count'] = df['Hashtags'].apply(lambda x: len(x.split()) if x else 0)\n",
    "\n",
    "df['username_length'] = df['Username'].apply(len)\n",
    "df['digit_count'] = df['Username'].str.count(r'\\d')\n",
    "\n",
    "df['tweet_length'] = df['Tweet'].apply(len)\n",
    "\n",
    "df['Verified'] = df['Verified'].astype(int)\n",
    "\n",
    "df['retweet_per_hashtag'] = df['Retweet Count'] / (df['hashtag_count'] + 1)\n",
    "\n",
    "# print(df.head)\n",
    "\n",
    "features = [\n",
    "    \"account_age_days\",\n",
    "    \"hashtag_count\",\n",
    "    \"username_length\",\n",
    "    \"digit_count\",\n",
    "    \"tweet_length\",\n",
    "    \"retweet_per_hashtag\",\n",
    "    \"Mention Count\",\n",
    "    \"Follower Count\",\n",
    "    \"Verified\"\n",
    "]\n",
    "\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"Bot Label\"]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaLZNvaX2Qnv"
   },
   "source": [
    "# splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1757274822299,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "VFASZ_myCATt",
    "outputId": "7a08d89d-19f3-403a-9e74-5adaeefca31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (40000, 9) (40000,)\n",
      "Test set shape: (10000, 9) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2vPPmjLb3U0"
   },
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1757274822354,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "IhF9EpX8DfM7",
    "outputId": "fd12034d-9990-4d20-e031-ad1ee51e2aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4919    0.4768    0.4842      4996\n",
      "           1     0.4932    0.5084    0.5007      5004\n",
      "\n",
      "    accuracy                         0.4926     10000\n",
      "   macro avg     0.4926    0.4926    0.4925     10000\n",
      "weighted avg     0.4926    0.4926    0.4925     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled =  scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edIqJcIZDJt_"
   },
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25021,
     "status": "ok",
     "timestamp": 1757274847376,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "sowUljrpLmOR",
    "outputId": "c87123af-97da-4bda-8481-48e1ad7e3f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth=20:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4949    0.4954    0.4951      4996\n",
      "           1     0.4957    0.4952    0.4955      5004\n",
      "\n",
      "    accuracy                         0.4953     10000\n",
      "   macro avg     0.4953    0.4953    0.4953     10000\n",
      "weighted avg     0.4953    0.4953    0.4953     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_limited = RandomForestClassifier(n_estimators=300, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf_limited.fit(X_train, y_train)\n",
    "print(\"Max_depth=20:\\n\")\n",
    "print(classification_report(y_test, rf_limited.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaXzWcS_N-Ch"
   },
   "source": [
    "# Gradient Boosting - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1331,
     "status": "ok",
     "timestamp": 1757274848704,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "U8A0gne1QnID",
    "outputId": "7365601f-1e2b-44d8-9a18-422c68e44a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 20014, number of negative: 19986\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 883\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500350 -> initscore=0.001400\n",
      "[LightGBM] [Info] Start training from score 0.001400\n",
      "LightGBM Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4943    0.5108    0.5024      4996\n",
      "           1     0.4947    0.4782    0.4863      5004\n",
      "\n",
      "    accuracy                         0.4945     10000\n",
      "   macro avg     0.4945    0.4945    0.4944     10000\n",
      "weighted avg     0.4945    0.4945    0.4944     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# LightGBM Classifier\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "y_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "print(\"LightGBM Results:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9_XaCYrXGEq"
   },
   "source": [
    "# Gradient Boosting - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1945,
     "status": "ok",
     "timestamp": 1757274850651,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "9jTGxLU7XXnk",
    "outputId": "a3a074d2-ebb6-462c-f242-6981286b6444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4978    0.5044    0.5011      4996\n",
      "           1     0.4986    0.4920    0.4953      5004\n",
      "\n",
      "    accuracy                         0.4982     10000\n",
      "   macro avg     0.4982    0.4982    0.4982     10000\n",
      "weighted avg     0.4982    0.4982    0.4982     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Results:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXE_AUHdYLxx"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397117,
     "status": "ok",
     "timestamp": 1757275247772,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "kv6D2OZNYNnD",
    "outputId": "b6636875-3d53-4977-b607-7a9a0ab659a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5003    0.5036    0.5019      4996\n",
      "           1     0.5011    0.4978    0.4994      5004\n",
      "\n",
      "    accuracy                         0.5007     10000\n",
      "   macro avg     0.5007    0.5007    0.5007     10000\n",
      "weighted avg     0.5007    0.5007    0.5007     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM Results:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i5E926vbKHR"
   },
   "source": [
    "# Neural Network - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52541,
     "status": "ok",
     "timestamp": 1757275300300,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "RHUhUwIEbORX",
    "outputId": "ed28849a-ff47-46b7-8530-6680f9cd7c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (MLP) Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4991    0.5088    0.5039      4996\n",
      "           1     0.4999    0.4902    0.4950      5004\n",
      "\n",
      "    accuracy                         0.4995     10000\n",
      "   macro avg     0.4995    0.4995    0.4995     10000\n",
      "weighted avg     0.4995    0.4995    0.4995     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),  # 2 hidden layers with 64 and 32 neurons\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "print(\"Neural Network (MLP) Results:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_U8nsixe5oW"
   },
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12390,
     "status": "ok",
     "timestamp": 1757275312684,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "r8AadPE9e9FX",
    "outputId": "0a7f62e9-d000-4b88-d2ac-6e97ff0a134b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Model Comparison:\n",
      "\n",
      "                        Accuracy  Precision (weighted)  Recall (weighted)  \\\n",
      "Logistic Regression       0.4926              0.492580             0.4926   \n",
      "Support Vector Machine    0.5007              0.500703             0.5007   \n",
      "Random Forest             0.4953              0.495300             0.4953   \n",
      "XGBoost                   0.4982              0.498205             0.4982   \n",
      "Multilayer Perceptron     0.4995              0.499508             0.4995   \n",
      "LightGBM                  0.4945              0.494507             0.4945   \n",
      "\n",
      "                        F1 (weighted)  Recall (Bot=1)  F1 (Bot=1)  \n",
      "Logistic Regression          0.492473        0.508393    0.500689  \n",
      "Support Vector Machine       0.500696        0.497802    0.499449  \n",
      "Random Forest                0.495300        0.495204    0.495451  \n",
      "XGBoost                      0.498181        0.492006    0.495273  \n",
      "Multilayer Perceptron        0.499457        0.490208    0.495006  \n",
      "LightGBM                     0.494366        0.478217    0.486333  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(name, model, X_test, y_test, scaled=False):\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, digits=4)\n",
    "    return { \"name\": name, \"report\": report }\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append(evaluate_model(\"Logistic Regression\", lr, X_test_scaled, y_test))\n",
    "results.append(evaluate_model(\"Random Forest\", rf_limited, X_test, y_test))\n",
    "results.append(evaluate_model(\"LightGBM\", lgb_clf, X_test, y_test))\n",
    "results.append(evaluate_model(\"XGBoost\", xgb_clf, X_test, y_test))\n",
    "results.append(evaluate_model(\"Support Vector Machine\", svm_clf, X_test_scaled, y_test))\n",
    "results.append(evaluate_model(\"Multilayer Perceptron\", mlp, X_test_scaled, y_test))\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    res[\"name\"]: {\n",
    "        \"Accuracy\": res[\"report\"][\"accuracy\"],\n",
    "        \"Precision (weighted)\": res[\"report\"][\"weighted avg\"][\"precision\"],\n",
    "        \"Recall (weighted)\": res[\"report\"][\"weighted avg\"][\"recall\"],\n",
    "        \"F1 (weighted)\": res[\"report\"][\"weighted avg\"][\"f1-score\"],\n",
    "        \"Recall (Bot=1)\": res[\"report\"][\"1\"][\"recall\"],\n",
    "        \"F1 (Bot=1)\": res[\"report\"][\"1\"][\"f1-score\"]\n",
    "    }\n",
    "    for res in results\n",
    "}).T\n",
    "\n",
    "print(\"\\n Final Model Comparison:\\n\")\n",
    "print(df_results.sort_values(\"F1 (Bot=1)\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15itbibTt-xM"
   },
   "source": [
    "# Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1757276298681,
     "user": {
      "displayName": "Avinash Dubey",
      "userId": "13452124553938126917"
     },
     "user_tz": -330
    },
    "id": "L5oj4pT8ufsX",
    "outputId": "292bbd48-4d73-4bee-e43d-61d51f55d8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model, scaler, and schema saved in backend/artifacts/\n",
      "Logistic Regression saved as backup\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "ARTIFACT_DIR = BASE_DIR.parent / \"backend\" / \"artifacts\"\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ---- best model so far ----\n",
    "with open(ARTIFACT_DIR / \"mlp_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mlp, f)\n",
    "\n",
    "# Saving the scaler used for MLP\n",
    "with open(ARTIFACT_DIR / \"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Saving the feature schema\n",
    "feature_columns = list(X.columns)\n",
    "with open(ARTIFACT_DIR / \"feature_columns.json\", \"w\") as f:\n",
    "    json.dump(feature_columns, f, indent=2)\n",
    "\n",
    "print(\"MLP model, scaler, and schema saved in backend/artifacts/\")\n",
    "\n",
    "# ---- Saving Logistic Regression Model as backup ----\n",
    "with open(ARTIFACT_DIR / \"logreg_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr, f)\n",
    "\n",
    "print(\"Logistic Regression saved as backup\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
